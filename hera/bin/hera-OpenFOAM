#! /usr/bin/env python
import argparse
import json
import sys
import shutil

version = sys.version_info[0]

from hera.simulations.openfoam.postprocess.etlVTK import recurseNode

if version == 2:
    from hera import openfoam

def load_handler(arguments):

    """
            This function handles the loading of the OpenFoam runs to the database.
            Converts hdf files results to .parquet, if exist.



        Parameters
        ----------

        arguments : a positional list pased by the user:
            arguments[0] - the path to the pipeline json file
            arguments[1] - the path to the main directory of the execute resulted files, as the metadata 'datadir' in the json file
            arguments[2] - the name given to the output folder and to the hdf files
            arguments[3] - the 'projecName' will be saved to the database


    """

    JSONpath = arguments[0]
    path = arguments[1]
    name = arguments[2]
    projectName = arguments[3]


    with open(JSONpath) as json_file:
        jsondata = json.load(json_file)
    metadata = jsondata["metadata"]  # Reading the metadata
    pipelines = jsondata["pipelines"]  # Reading the pipelines


    for i,node in enumerate(pipelines):
        Tree=[]
        Tree.append(node)
        recurseNode(Tree,node,pipelines[node],metadata,pipelines, path=path,name=name,projectName=projectName)

    #   Delete hdf directory
    if args.keepHDF:
        print("deleting HDF files")
        shutil.rmtree("%s/%s/hdf" % (path, name), ignore_errors=True)
        shutil.rmtree("%s/%s/meta.json" % (path, name), ignore_errors=True)


def executePipeline_handler(arguments):

    """
            This function handles the execution of the pipeline.

        Parameters
        ----------

        arguments : a positional list pased by the user:
            arguments[0] - the path to the pipeline json file
            arguments[1] - the name which will be given to the output folder and to the hdf files
            arguments[2] - the path to the directory of the openFOAM project contains the results
            arguments[3] - optional. 'Decomposed Case' for parallel cases or 'Reconstructed Case' for single processor cases. default is 'Decomposed Case'.
            arguments[4] - optional. a connection string to paraview server.default is None (work locally).
            arguments[5] - optional. the number of time steps will be saved to single file. default is 100

    """

    JSONpath = arguments[0]
    name = arguments[1]
    casePath = arguments[2]
    caseType = arguments[3] if len(arguments) > 3 else "Decomposed Case"
    servername = arguments[4] if len(arguments) > 4 else None
    tsBlockNum = int(arguments[5]) if len(arguments) > 5 else 100

    with open(JSONpath) as json_file:
        data = json.load(json_file)
    vtkpipe = openfoam.VTKpipeline(name=name, pipelineJSON=data, casePath=casePath, caseType=caseType, servername=servername)
    vtkpipe.execute("mainReader", tsBlockNum=tsBlockNum)

    # (name
    #  ="test", pipelineJSON=data, casePath="/home/ofir/Projects/openFoamUsage/askervein", caseType="Reconstructed Case")


if __name__ =="__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('command', nargs=1, type=str)
    parser.add_argument('args', nargs='*', type=str)
    parser.add_argument('-keepHDF', action='store_false')

    args = parser.parse_args()

    commands = ["load"]


    globals()['%s_handler' % args.command[0]](args.args)