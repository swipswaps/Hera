{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding data\n",
    "\n",
    "This notebook shows how to add a document to database with the datalayer.\n",
    "\n",
    "First, we will create a synthetic dataframe that we want to save as a database record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           date      time  value\n",
      "date_time                                       \n",
      "2016-11-10 22:00:00  2016-11-10  22:00:00     90\n",
      "2016-11-10 23:00:00  2016-11-10  23:00:00     91\n",
      "2016-11-11 00:00:00  2016-11-11  00:00:00     80\n",
      "2016-11-11 01:00:00  2016-11-11  01:00:00     87\n",
      "2016-11-11 02:00:00  2016-11-11  02:00:00     84\n",
      "2016-11-11 03:00:00  2016-11-11  03:00:00     94\n",
      "2016-11-11 04:00:00  2016-11-11  04:00:00     91\n",
      "2016-11-11 05:00:00  2016-11-11  05:00:00     94\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.DataFrame(dict(date = [\"2016-11-10\", \"2016-11-10\", \"2016-11-11\", \"2016-11-11\",\"2016-11-11\",\"2016-11-11\",\"2016-11-11\", \"2016-11-11\" ],\n",
    "                           time = [\"22:00:00\", \"23:00:00\", \"00:00:00\", \"01:00:00\", \"02:00:00\", \"03:00:00\", \"04:00:00\", \"05:00:00\"],\n",
    "                           value = [90, 91, 80, 87, 84,94, 91, 94]))\n",
    "df['date_time'] = pandas.to_datetime(df['date'] + ' ' + df['time'])\n",
    "df=df.set_index('date_time')\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several parameters must be given for any document, and must be defined in order to add new data.\n",
    "These parameters are the ones given in the next example.\n",
    "In addition, one may add any other parameters to the document.\n",
    "\n",
    "The data is added using the next method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measurements object\n"
     ]
    }
   ],
   "source": [
    "from hera import datalayer\n",
    "\n",
    "projectName = \"addDataExample\" # must be a string\n",
    "documentType = \"ExampleData\" # must be a string\n",
    "desc = {\"description_A\": \"A\", \"description_B\": \"B\"} # must be a dictionary. Contains descriptors of the data.\n",
    "dataFormat = datalayer.datatypes.JSON_PANDAS # other types are givnen the documentation. \n",
    "resource = df.to_json() # A dynamic field, can points to a specific file in a folder (path) or contain the data itself.\n",
    "\n",
    "new_doc=datalayer.Measurements.addDocument(projectName=projectName, desc=desc, type=documentType, dataFormat=dataFormat, resource=resource)\n",
    "print(new_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the desc dictionary may not contain a key named \"type\".\n",
    "The allowed data formats are detailed in the hera.datalayer.datatypes:\n",
    "\n",
    "-    STRING : Any string. \n",
    "-    TIME   : any date/time object\n",
    "-    HDF    : a dask or pandas in hdf file format. \n",
    "-    NETCDF_XARRAY : an xarray netcdf. \n",
    "-    JSON_DICT  :  JSON as python dict \n",
    "-    JSON_PANDAS :  JSON as pandas.DataFrame \n",
    "-    GEOPANDAS   : a GIS-file format. returns as geopandas.GISDataFrame \n",
    "-    PARQUET    : dask or pandas in parquet format. \n",
    "-    IMAGE      : any Image data format. Preferably PNG. \n",
    "\n",
    "They indicate how to read the data, and therefore must correspond to the type of data located in the resource.\n",
    "\n",
    "The added document can be loaded as presented in the \"Getting data\" notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data\n",
    "This notebook shows how to get the data with the datalayer.\n",
    "\n",
    "Let's read the synthetic database record we saved in the \"Adding Data\" example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the datalayer, you can get the data that fits your requirments. \n",
    "Below we see an example of getting the document of the experimental data between 2 dates of Haifa campaign in station Check_Post, instrument Sonic, height 9(m)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projectName = 'Haifa'\n",
    "# station = 'Check_Post'\n",
    "# instrument = 'Sonic'\n",
    "# height = 9\n",
    "\n",
    "# doc = datalayer.Measurements.getDocuments(projectName=projectName,\n",
    "#                                       station=station,\n",
    "#                                       instrument=instrument,\n",
    "#                                       height=height)\n",
    "\n",
    "projectName = \"addDataExample\"\n",
    "desc=dict(description_A = \"A\")\n",
    "\n",
    "docList = datalayer.Measurements.getDocuments(projectName=projectName,**desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result obtained from the query is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Measurements: Measurements object>]\n"
     ]
    }
   ],
   "source": [
    "print(docList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now read the data from the 'doc' and perform another query (for example, on a date range):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          date      time  value\n",
      "2016-11-10 23:00:00 2016-11-10  23:00:00     91\n",
      "2016-11-11 00:00:00 2016-11-11  00:00:00     80\n",
      "2016-11-11 01:00:00 2016-11-11  01:00:00     87\n",
      "2016-11-11 02:00:00 2016-11-11  02:00:00     84\n"
     ]
    }
   ],
   "source": [
    "start = pandas.Timestamp('2016-11-10 23:00:00')\n",
    "end = pandas.Timestamp('2016-11-11 02:00:00')\n",
    "data=(docList[docList.count() - 1].getData())\n",
    "data=data[start:end]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have got our data as dask dataframe, we can convert it to pandas dataframe with the '.compute()' function, like this: data = data.compute()\n",
    "\n",
    "Alternatively you can use the argument 'usePandas' with value True to get data directly as pandas and not dask.\n",
    "(**Should be used only when the data is small**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update data description\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resource is: {\"date\":{\"1478815200000\":\"2016-11-10\",\"1478818800000\":\"2016-11-10\",\"1478822400000\":\"2016-11-11\",\"1478826000000\":\"2016-11-11\",\"1478829600000\":\"2016-11-11\",\"1478833200000\":\"2016-11-11\",\"1478836800000\":\"2016-11-11\",\"1478840400000\":\"2016-11-11\"},\"time\":{\"1478815200000\":\"22:00:00\",\"1478818800000\":\"23:00:00\",\"1478822400000\":\"00:00:00\",\"1478826000000\":\"01:00:00\",\"1478829600000\":\"02:00:00\",\"1478833200000\":\"03:00:00\",\"1478836800000\":\"04:00:00\",\"1478840400000\":\"05:00:00\"},\"value\":{\"1478815200000\":90,\"1478818800000\":91,\"1478822400000\":80,\"1478826000000\":87,\"1478829600000\":84,\"1478833200000\":94,\"1478836800000\":91,\"1478840400000\":94}}\n",
      "The description is: {'description_A': 'A', 'description_B': 'B'}\n"
     ]
    }
   ],
   "source": [
    "print('The resource is: %s' %docList[0].resource)\n",
    "print('The description is: %s' %docList[0].desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docobj = docList[0]\n",
    "newdata1 = dict(docobj.desc)\n",
    "newdata1['description_C'] = \"C1\"\n",
    "resource1 = \"resource1\"\n",
    "\n",
    "\n",
    "newdata2 = dict(docobj.desc)\n",
    "newdata2['description_C'] = \"C1\"\n",
    "resource2 = \"resource2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1: set the new attributes in the object and save. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docobj.resource = resource1\n",
    "docobj.desc = newdata\n",
    "docobj.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check that the database was updated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resource is: resource1\n",
      "The description is: {'description_A': 'A', 'description_B': 'B', 'description_C': 'C1'}\n"
     ]
    }
   ],
   "source": [
    "after_update_docList = datalayer.Measurements.getDocuments(projectName=projectName,**desc)\n",
    "after_update_docobj = docList[0]\n",
    "print('The resource is: %s' %after_update_docobj.resource)\n",
    "print('The description is: %s' %after_update_docobj.desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docobj = docList[0]\n",
    "\n",
    "docobj.update(resource=\"resource2\",desc=docdesc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we update the object and fetch the current values from the database: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docobj.reload()\n",
    "print('The resource is: %s' %docobj.resource)\n",
    "print('The description is: %s' %docobj.desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resource is: resource2\n",
      "The description is: {'description_A': 'A', 'description_B': 'B', 'description_C': 'C2'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Project \n",
    "\n",
    "Using the Project class simplifies the access to the different documents of the project. \n",
    "\n",
    "Define the project with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hera.datalayer.collection.Simulations_Collection at 0x7f45c0375c18>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hera.datalayer import Project \n",
    "\n",
    "p = Project(projectName=\"testProject\")\n",
    "\n",
    "p.simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
